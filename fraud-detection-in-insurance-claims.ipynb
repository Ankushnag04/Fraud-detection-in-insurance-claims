{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Fraud Detection"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS1B1mo09UtC5o_GcLgxRAg4Q6rd3ehoR9r0Z-9lI55nyGp4F-GRA\" width=\"400px\">"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip install joypy","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install bubbly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install plotly_express","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing the Libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# for some basic operations\nimport numpy as np \nimport pandas as pd \nimport joypy\n\n# for visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas import plotting\nfrom pandas.plotting import parallel_coordinates\n\n# for interactive visualizations\nimport plotly\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n\n# for animated visualizations\nfrom bubbly.bubbly import bubbleplot\nimport plotly_express as px\n\n# for providing path\nimport os\nprint(os.listdir(\"../input\"))\n\n# for modelling\nimport sklearn\nimport imblearn\n\n# for model explanation\nimport shap \nimport eli5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading the Dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# let's import the data\ndata = pd.read_csv('../input/insurance_claims.csv')\n\n# let's take a look at the data\npd.set_option('display.max_columns', None)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the shape of the dataset\n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# let's get the information about the dataset\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Descriptive Statistics"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# let's describe the data\n# It will demonstrate the count, mean, std dev, min, max, etc values for the Numerical features present in the data.\n\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the correlation\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the covriance\ndata.cov()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check whether the data has any null values or not.\n\n# but there are '?' in the datset which we have to remove by NaN Values\ndata = data.replace('?',np.NaN)\n\ndata.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing value treatment using fillna\n\n# we will replace the '?' by the most common collision type as we are unaware of the type.\ndata['collision_type'].fillna(data['collision_type'].mode()[0], inplace = True)\n\n# It may be the case that there are no responses for property damage then we might take it as No property damage.\ndata['property_damage'].fillna('NO', inplace = True)\n\n# again, if there are no responses fpr police report available then we might take it as No report available\ndata['police_report_available'].fillna('NO', inplace = True)\n\ndata.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualizations"},{"metadata":{},"cell_type":"markdown","source":"**Scatter Plot between Policy annual premium vs total claim amount**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# plotting a scatter plot\n\nfig = px.scatter(data, x = 'total_claim_amount', y = 'policy_annual_premium', color = 'insured_sex',\n                marginal_x = 'rug', marginal_y = 'histogram')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_matrix(data, dimensions=[\"injury_claim\", \"property_claim\", \"vehicle_claim\"],\n                        color = \"insured_sex\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.parallel_categories(data, color=\"total_claim_amount\", color_continuous_scale=px.colors.sequential.Inferno)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fraud = data['fraud_reported'].value_counts()\n\nlabel_fraud = fraud.index\nsize_fraud = fraud.values\n\ncolors = ['silver', 'gold']\ntrace = go.Pie(\n         labels = label_fraud, values = size_fraud, marker = dict(colors = colors), name = 'Frauds', hole = 0.3)\n\n\ndf = [trace]\n\nlayout = go.Layout(\n           title = 'Distribution of Frauds')\n\nfig = go.Figure(data = df, layout = layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = joypy.joyplot(data,\n                         column = ['incident_hour_of_the_day','number_of_vehicles_involved', 'witnesses'],\n                         by = 'incident_city',\n                         ylim = 'own',\n                         figsize = (20, 10),\n                         alpha = 0.5, \n                         legend = True)\n\nplt.title('Incident hour, No. of vehicles, witnesses vs Incident City', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.stripplot(data['property_damage'], data['property_claim'], palette = 'bone')\nplt.title('Incident Type vs Vehicle Claim', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.boxenplot(data['incident_type'], data['vehicle_claim'], palette = 'pink')\nplt.title('Incident Type vs Vehicle Claim', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"incident = pd.crosstab(data['incident_city'], data['incident_type'])\ncolors = plt.cm.Blues(np.linspace(0, 1, 5))\nincident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n                                                           stacked = False,\n                                                           figsize = (15, 7),\n                                                           color = colors)\n\nplt.title('Incident Type vs Collision Type', fontsize = 20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nincident = pd.crosstab(data['incident_type'], data['incident_severity'])\ncolors = plt.cm.summer(np.linspace(0, 1, 5))\nincident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n                                                           stacked = False,\n                                                           figsize = (15, 7),\n                                                           color = colors)\n\nplt.title('Incident Type vs Collision Type', fontsize = 20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nincident = pd.crosstab(data['incident_type'], data['collision_type'])\ncolors = plt.cm.inferno(np.linspace(0, 1, 5))\nincident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n                                                           stacked = True,\n                                                           figsize = (15, 7),\n                                                           color = colors)\n\nplt.title('Incident Type vs Collision Type', fontsize = 20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# let's check the insured hobbies\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.countplot(data['insured_occupation'], palette = 'PuRd')\nplt.title('Different Types of Occupation of Insured Customers', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# let's check the insured hobbies\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.countplot(data['insured_hobbies'], palette = 'cool')\nplt.title('Different Types of Hobbies of Insured Customers', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# let's check the incident types\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.countplot(data['incident_type'], palette = 'spring')\nplt.title('Different Types of Incidents', fontsize = 20)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# swarm plot\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nsns.swarmplot(data['policy_state'], data['total_claim_amount'], palette = 'copper')\nplt.title('Policy State vs Total Claim Amount', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Plot\nplt.figure(figsize=(20, 10), dpi= 80)\n\nparallel_coordinates(data[['total_claim_amount','injury_claim', 'property_claim','vehicle_claim','fraud_reported']],\n                     'fraud_reported',  colormap = 'copper')\n\n# Lighten borders\nplt.gca().spines[\"top\"].set_alpha(0)\nplt.gca().spines[\"bottom\"].set_alpha(.3)\nplt.gca().spines[\"right\"].set_alpha(0)\nplt.gca().spines[\"left\"].set_alpha(.3)\n\nplt.title('DC', fontsize = 20)\nplt.grid(alpha=0.3)\n\n\nplt.suptitle('total claim, Injury claim, Property claim, vehicle claim vs Fraud Reported', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nfigure = bubbleplot(dataset = data, x_column = 'policy_annual_premium', y_column = 'total_claim_amount', \n    bubble_column = 'insured_sex', time_column = 'auto_year', size_column = 'months_as_customer', color_column = 'insured_sex', \n    x_title = \"Annual Policy Premium\", y_title = \"Total Claim Amount\", title = 'Annual Premium vs Total Claim Amount vs Months as Customer',\n    x_logscale = False, scale_bubble = 3, height = 650)\n\npy.iplot(figure, config={'scrollzoom': True})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ntrace = go.Histogram(\n          x = data['insured_education_level'],\n          name = 'Marvel',\n          opacity = 0.75,\n          marker = dict(\n                 color = 'rgb(195, 195, 145, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Education Level of the Customers')\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ntrace = go.Histogram(\n          x = data['insured_occupation'],\n          name = 'Marvel',\n          opacity = 0.75,\n          marker = dict(\n                 color = 'rgb(15, 255, 185, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Occupation of the Customers')\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sex = data['insured_sex'].value_counts()\nrel = data['insured_relationship'].value_counts()\n\nlabel_sex = sex.index\nsize_sex = sex.values\n\nlabel_rel = rel.index\nsize_rel = rel.values\n\ncolors = ['aqua', 'gold']\ntrace = go.Pie(\n         labels = label_sex, values = size_sex, marker = dict(colors = colors), name = 'Gender', hole = 0.3)\n\ncolors2 = ['pink', 'lightblue','lightgreen','grey','red']\ntrace2 = go.Pie(labels = label_rel, values = size_rel, marker = dict(colors = colors2), name = 'Relationship',\n                hole = 0.3)\n\ndf = [trace]\ndf2 = [trace2]\n\nlayout1 = go.Layout(\n           title = 'Gender of the Customers')\nlayout2 = go.Layout(\n           title = 'Relationship')\n\nfig = go.Figure(data = df, layout = layout1)\nfig2 = go.Figure(data = df2, layout = layout2)\npy.iplot(fig)\npy.iplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\ntrace = go.Violin(\n          x = data['insured_sex'],\n          y = data['insured_zip'],\n          name = 'Gender vs Insured Zip',\n          opacity = 0.75,\n          marker = dict(\n                 color = 'rgb(215, 5, 185, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Gender vs Insured Zip')\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"trace = go.Box(\n          x = data['auto_make'],\n          y = data['vehicle_claim'],\n          opacity = 0.7,\n          marker = dict(\n                 color = 'rgb(215, 195, 5, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Automobile Company vs Vehicle Claim')\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Histogram(\n          x = data['policy_annual_premium'],\n          \n          #fill = 'tozeroy',\n          marker = dict(\n                 color = 'rgb(100, 75, 25, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Distribution of Annual Policy among the Customers',\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Count')\n        ))\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trace = go.Histogram(\n          x = data['age'],\n          \n          #fill = 'tozeroy',\n          marker = dict(\n                 color = 'rgb(215, 245, 5, 0.5)'\n          )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Distribution of Age among the Customers',\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Count')\n        ))\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trace = go.Scatter3d(\n    x = data['age'],\n    y = data['property_claim'],\n    z = data['vehicle_claim'],\n    mode = 'markers',\n    marker = dict(\n         size = 10,\n         color = data['age']\n    )\n)\n\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Cholestrol vs Heart Rate vs Age',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    ),\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Property_claim'),\n            zaxis = dict(title  = 'Vehicle_claim')\n        )\n    \n)\nfig = go.Figure(data = df, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's extrat days, month and year from policy bind date\n\ndata['policy_bind_date'] = pd.to_datetime(data['policy_bind_date'], errors = 'coerce')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's encode the fraud report to numerical values\n\ndata['fraud_reported'] = data['fraud_reported'].replace(('Y','N'),(0,1))\n\n# checking the values of fraud reported\n# data['fraud_reported'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['auto_model','fraud_reported']].groupby(['auto_model'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for auto make\n\ndata['auto_make'] = data['auto_make'].replace(('3 Series','RSX','Malibu','Wrangler','Pathfinder','Ultima','Camry',\n                'Corolla','CRV','Legacy','Neon','95','TL','93','MDX','Accord','Grand Cherokee','Escape','E4000',\n            'A3','Highlander','Passat','92x','Jetta','Fusion','Forrestor','Maxima','Impreza','X5','RAM','M5','A5',\n                'Civic','F150','Tahaoe','C300','ML350','Silverado','X6'),\n                (0.95,0.91, 0.90,0.88,0.87,0.86,0.855,0.85,0.85,0.84,0.83,0.81,0.80,0.80,0.78,0.77,0.76,0.75,0.74,\n                 0.73,0.72,0.72,0.71,0.71,0.71,0.71,0.70,0.70,0.69,0.67,0.66,0.65,0.64,0.63,0.62,0.61,0.60,0.59,0.56))\n\n# let's check the values\n# data['auto_make'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation auto make with the target\n\ndata[['auto_make','fraud_reported']].groupby(['auto_make'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for auto make\n\ndata['auto_make'] = data['auto_make'].replace(('Jeep','Nissan','Toyota','Accura','Saab','Suburu',\n                                'Dodge','Honda','Chevrolet','BMW','Volkswagen','Audi','Ford','Mercedes'),\n                                              (0.84,0.82,0.81,0.80,0.77,0.76,0.75,0.74,0.73,0.72,0.71,0.69,0.69,0.66))\n\n# let's check the values\n# data['auto_make'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['police_report_available','fraud_reported']].groupby(['police_report_available'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for property damage\n\ndata['police_report_available'] = data['police_report_available'].replace(('NO','YES'),(0.77,0.74))\n\n# let's check the values\n# data['police_report_available'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['property_damage','fraud_reported']].groupby(['property_damage'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for property damage\n\ndata['property_damage'] = data['property_damage'].replace(('NO','YES'),(0.76,0.74))\n\n# let's check the values\n# data['property_damage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['incident_city','fraud_reported']].groupby(['incident_city'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's do target encoding for incident city\n\ndata['incident_city'] = data['incident_city'].replace(('Northbrook','Riverwood','Northbend','Springfield',\n                                    'Hillsdale','Columbus','Arlington'),(0.78,0.77,0.76,0.75,0.74,0.73,0.71))\n\n# let's check the values\n# data['incident_city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['incident_state','fraud_reported']].groupby(['incident_state'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for incident state\n\ndata['incident_state'] = data['incident_state'].replace(('WV','NY','VA','PA','SC','NC','OH'),\n                                                        (0.82,0.77,0.76,0.73,0.70,0.69,0.56))\n\n# checking the values\n# data['incident_state'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of authorities_contacted with the target\n\ndata[['authorities_contacted','fraud_reported']].groupby(['authorities_contacted'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for authorities contacted\n\ndata['authorities_contacted'] = data['authorities_contacted'].replace(('None','Police','Fire','Ambulance','Other'),\n                                                                      (0.94,0.79,0.73,0.70,0.68))\n\n# let's check the values\n#data['authorities'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of incident_severity with the target\n\ndata[['incident_severity','fraud_reported']].groupby(['incident_severity'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for incident severity\n\ndata['incident_severity'] = data['incident_severity'].replace(('Trivial Damage','Minor Damage','Total Loss',\n                                                              'Major Damage'),(0.94,0.89,0.87,0.39))\n\n# let's check the values\n# data['incident_severity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of collision_type with the target\n\ndata[['collision_type','fraud_reported']].groupby(['collision_type'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for collision type\n\ndata['collision_type'] = data['collision_type'].replace(('Rear Collision', 'Side Collision', 'Front Collision'),\n                                                        (0.78,0.74,0.72))\n\n# let's check the values of collision type\n# data['collision_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the correlation of incident_type with the target\n\ndata[['incident_type','fraud_reported']].groupby(['incident_type'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoing for incident type\n\ndata['incident_type'] = data['incident_type'].replace(('Vehicle Theft','Parked Car','Multi-vehicle Collision',\n                                'Single Vehicle Collision'),(0.91, 0.90, 0.72,0.70))\n\n# let's check the values\n#data['incident_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['incident_date'] = pd.to_datetime(data['incident_date'], errors = 'coerce')\n\n# extracting days and month from date\ndata['incident_month'] = data['incident_date'].dt.month\ndata['incident_day'] = data['incident_date'].dt.day\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's know the relation between insured_relationship and fraud reported\n\ndata[['insured_relationship','fraud_reported']].groupby(['insured_relationship'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's do target encoding for insured relationship\n\ndata['insured_relationship'] = data['insured_relationship'].replace(('husband','own-child','unmarried',\n                                        'not-in-family','wife','other-relative'),(0.79,0.78,0.75,0.74,0.72,0.70))\n\n#data['insured-relationship'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's know the relation between insured_hobbies and fraud reported\n\ndata[['insured_hobbies','fraud_reported']].groupby(['insured_hobbies'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for insured_hobbies\n\ndata['insured_hobbies'] = data['insured_hobbies'].replace(('camping', 'kayaking', 'golf','dancing',\n        'bungie-jumping','movies', 'basketball','exercise','sleeping','video-games','skydiving','paintball',\n            'hiking','base-jumping','reading','polo','board-games','yachting', 'cross-fit','chess'),(0.91, 0.90,\n                0.89, 0.88,0.84,0.83,0.82,0.81,0.805,0.80,0.78,0.77,0.76,0.73,0.73,0.72,0.70,0.69,0.25,0.17))\n\n#data['insured_hobbies'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's know the relation between insured_occupation and fraud reported\n\ndata[['insured_occupation','fraud_reported']].groupby(['insured_occupation'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding for insured_occupation\n\ndata['insured_occupation'] = data['insured_occupation'].replace(('other-service','priv-house-serv',\n                        'adm-clerical','handlers-cleaners','prof-specialty','protective-serv',\n                'machine-op-inspct','armed-forces','sales','tech-support','transport-moving','craft-repair',\n                    'farming-fishing','exec-managerial'),(0.84, 0.84,0.83, 0.79,0.78,0.77,0.76,0.75,0.72,0.71,\n                                                          0.705,0.70,0.69,0.63))\n# data['insured_occupation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's know the relation of insured_education_level with faud_reported\n\ndata[['insured_education_level','fraud_reported']].groupby(['insured_education_level'], \n                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's perform target encoding\n\ndata['insured_education_level'] = data['insured_education_level'].replace(('Masters', 'High School','Associate',\n                                        'JD','College', 'MD','PhD'),(0.78,0.77,0.76,0.74,0.73,0.72,0.71))\n#data['insured_education_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets know the relation of insured sex and fraud reported\n\ndata[['insured_sex','fraud_reported']].groupby(['insured_sex'], as_index = False).mean().sort_values(\n    by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target encoding for sex\n\ndata['insured_sex'] = data['insured_sex'].replace(('FEMALE','MALE'),(0.76,0.73))\n#data['insured_sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# csl - combined single limit\n\n'''CSL is a single number that describes the predetermined limit for the combined total of the Bodily Injury \nLiability coverage and Property Damage Liability coverage per occurrence or accident.'''\n\n# lets know the relation of policy state and fraud reported\n\ndata[['policy_csl','fraud_reported']].groupby(['policy_csl'], as_index = False).mean().sort_values(\n    by = 'fraud_reported', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target encoding for policy_csl\n\ndata['policy_csl'] = data['policy_csl'].replace(('500/1000','100/300','250/500'),(0.78,0.74,0.73))\n\n# check the values\n# data['policy_csl'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# lets know the relation of policy state and fraud reported\n\ndata[['policy_state','fraud_reported']].groupby(['policy_state'], as_index = False).mean().sort_values(\n    by = 'fraud_reported', ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target encoding for policy_csl\n\ndata['policy_state'] = data['policy_state'].replace(('IL','IN','OH'),(0.77,0.745,0.74))\n\n# check the values\n# data['policy_state'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's delete unnecassary columns\n\ndata = data.drop(['policy_number','policy_bind_date', 'incident_date','incident_location','auto_model'], axis = 1)\n\n# let's check the columns after deleting the columns\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's split the data into dependent and independent sets\n\nx = data.drop(['fraud_reported'], axis = 1)\ny = data['fraud_reported']\n\nprint(\"Shape of x :\", x.shape)\nprint(\"Shape of y :\", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's split the dataset into train and test sets\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n\nprint(\"Shape of x_train :\", x_train.shape)\nprint(\"Shape of x_test :\", x_test.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of y_test :\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 10)\nsns.heatmap(x_train.corr(), cmap = 'copper')\nplt.title('Heat Map for Correlations', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling with Ensemble of Samplers"},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier\n\nfrom imblearn.ensemble import BalancedRandomForestClassifier \nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n                 \n\nmodel = BalancedRandomForestClassifier(n_estimators = 100, random_state = 0)\n\nmodel.fit(x_train, y_train)\ny_pred_rf = model.predict(x_test)\n\nprint(\"Training Accuracy: \", model.score(x_train, y_train))\nprint('Testing Accuarcy: ', model.score(x_test, y_test))\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)\n\n# making a confusion matrix\nplt.rcParams['figure.figsize'] = (5, 5)\ncm = confusion_matrix(y_test, y_pred_rf)\nsns.heatmap(cm, annot = True, cmap = 'spring')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Easy Ensemble Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Easy Ensemble Classifier\n\nfrom imblearn.ensemble import EasyEnsembleClassifier \nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n                 \n\nmodel1 = EasyEnsembleClassifier(n_estimators = 100, random_state = 0)\n\nmodel1.fit(x_train, y_train)\ny_pred_ef = model1.predict(x_test)\n\nprint(\"Training Accuracy: \", model1.score(x_train, y_train))\nprint('Testing Accuarcy: ', model1.score(x_test, y_test))\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_ef)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_ef)\nsns.heatmap(cm, annot = True, cmap = 'copper')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bagging Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest with Bagging Classifier\n\nfrom imblearn.ensemble import BalancedBaggingClassifier \nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n                 \n\nmodel2 = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(),\n                                 sampling_strategy = 'auto',\n                                 replacement = False,\n                                 random_state = 0)\n\nmodel2.fit(x_train, y_train)\ny_pred_bc = model2.predict(x_test)\n\nprint(\"Training Accuracy: \", model2.score(x_train, y_train))\nprint('Testing Accuarcy: ', model2.score(x_test, y_test))\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_bc)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_bc)\nsns.heatmap(cm, annot = True, cmap = 'Purples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Boosting the Predictions of above Models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# boosting\n\ny_pred = y_pred_rf*0.5 + y_pred_ef*0.2 + y_pred_bc*0.3\n\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred <= 0.5] = 0\npef\n# making a classification report\ncr = classification_report(y_test,  y_pred)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot = True, cmap = 'Reds')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voting Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nvote_est = [ \n    ('brf', BalancedRandomForestClassifier()),\n    ('bc', BalancedBaggingClassifier()),\n    ('eec',EasyEnsembleClassifier())]\n\nvoting = VotingClassifier(estimators = vote_est , voting = 'soft')\nvoting.fit(x_train, y_train)\n\ny_pred = voting.predict(x_test).astype(int)\n\n# making a classification report\ncr = classification_report(y_test,  y_pred)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot = True, cmap = 'magma')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Sampling Techniques"},{"metadata":{},"cell_type":"markdown","source":"**Under Sampling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frauds = np.array(data[data['fraud_reported'] == 0].index)\nno_frauds = len(frauds)\n\nprint(no_frauds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_indices = data[data['fraud_reported'] == 1]\nno_normal_indices = len(normal_indices)\n\nprint(no_normal_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrandom_normal_indices = np.random.choice(no_normal_indices, size = no_frauds, replace = True)\nrandom_normal_indices = np.array(random_normal_indices)\n\nprint(len(random_normal_indices))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"under_sample = np.concatenate([frauds, random_normal_indices])\nprint(len(under_sample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# creating the undersample data\n\nundersample_data = data.iloc[under_sample, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the undersample dataset into x and y sets\n\nx_u = undersample_data.iloc[:, undersample_data.columns != 'fraud_reported'] \ny_u = undersample_data.iloc[:, undersample_data.columns == 'fraud_reported']\n\nprint(x_u.shape)\nprint(y_u.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train1, x_test1, y_train1, y_test1 = train_test_split(x_u, y_u, test_size = 0.2, random_state = 0)\n\nprint(x_train1.shape)\nprint(y_train1.shape)\nprint(x_test1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standardization\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nx_train1 = sc.fit_transform(x_train1)\nx_test1 = sc.transform(x_test1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_u = RandomForestClassifier()\nmodel_u.fit(x_train1, y_train1)\n\ny_pred = model_u.predict(x_test1)\n\nprint(\"Training Accuracy: \", model_u.score(x_train1, y_train1))\nprint('Testing Accuarcy: ', model_u.score(x_test1, y_test1))\n\n# confusion matrix\ncm = confusion_matrix(y_test1, y_pred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test1, y_pred)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Over Sampling with SMOTE** "},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nx_resample, y_resample  = SMOTE().fit_sample(x, y.values.ravel())\n\nprint(x_resample.shape)\nprint(y_resample.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train2, x_test2, y_train2, y_test2 = train_test_split(x_resample, y_resample, test_size = 0.2, random_state = 0)\n\nprint(x_train2.shape)\nprint(y_train2.shape)\nprint(x_test2.shape)\nprint(y_test2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# standardization\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nx_train2 = sc.fit_transform(x_train2)\nx_test2 = sc.transform(x_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel_o = RandomForestClassifier()\nmodel_o.fit(x_train2, y_train2)\n\ny_pred = model_o.predict(x_test2)\n\nprint(\"Training Accuracy: \", model_o.score(x_train2, y_train2))\nprint('Testing Accuarcy: ', model_o.score(x_test2, y_test2))\n\n# confusion matrix\ncm = confusion_matrix(y_test2, y_pred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test2, y_pred)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Explanation for Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the importance of each attributes\n\nfrom eli5.sklearn import PermutationImportance\n\n\nperm = PermutationImportance(model, random_state = 0).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots #for partial plots\n\nbase_features = x_train.columns.values.tolist()\n\nfeat_name = 'incident_severity'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots #for partial plots\n\nbase_features = x_train.columns.values.tolist()\n\nfeat_name = 'collision_type'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots #for partial plots\n\nbase_features = x_train.columns.values.tolist()\n\nfeat_name = 'incident_severity'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots #for partial plots\n\nbase_features = x_train.columns.values.tolist()\n\nfeat_name = 'insured_zip'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots #for partial plots\n\nbase_features = x_train.columns.values.tolist()\n\nfeat_name = 'age'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's see the shap values\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(x_test)\n\nshap.summary_plot(shap_values[1], x_test, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values[1], x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's create a function to check the patient's conditions\n\ndef fraud_analysis(model, fraud):\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(fraud)\n    shap.initjs()\n    return shap.force_plot(explainer.expected_value[1], shap_values[1], fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's do some real time prediction for patients\n\nfraud = x_test.iloc[1,:].astype(float)\nfraud_analysis(model, fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud = x_test.iloc[2,:].astype(float)\nfraud_analysis(model, fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud = x_test.iloc[3,:].astype(float)\nfraud_analysis(model, fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud = x_test.iloc[4,:].astype(float)\nfraud_analysis(model, fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud = x_test.iloc[5,:].astype(float)\nfraud_analysis(model, fraud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values = explainer.shap_values(x_train.iloc[:50])\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], x_test.iloc[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}